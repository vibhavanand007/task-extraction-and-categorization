{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing required lib:"
      ],
      "metadata": {
        "id": "U8-xh1U130gN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "kTA7awjEw-eG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manually download necessary resources"
      ],
      "metadata": {
        "id": "qNcLJJ-I37yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SkxZ4MxxTID",
        "outputId": "7c1d0652-406c-48ec-d774-fafdd6b34dde"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbT4A8C2xg35",
        "outputId": "32d54b55-75b2-4809-e3bc-2aa9726b8e33"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['python', '-m', 'spacy', 'download', 'en_core_web_sm'], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing: Step 1"
      ],
      "metadata": {
        "id": "qg1WAQSh4GWI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr9eJiCNw40z",
        "outputId": "9c294888-4d56-47dd-e415-48084b5a4a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rahul wakes early buy snacks us']\n"
          ]
        }
      ],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Cleans the input text by removing special characters, tokenizing, and filtering stopwords.\n",
        "    \"\"\"\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove special characters\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
        "\n",
        "    # Tokenize into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    cleaned_sentences = []\n",
        "    for sentence in sentences:\n",
        "        words = sentence.split()\n",
        "        filtered_words = [word for word in words if word not in stop_words]\n",
        "        cleaned_sentences.append(\" \".join(filtered_words))\n",
        "\n",
        "    return cleaned_sentences\n",
        "\n",
        "# Example Input\n",
        "text = \"Rahul wakes up early. He has to buy snacks for all of us.\"\n",
        "print(preprocess_text(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task Identification: Step 2"
      ],
      "metadata": {
        "id": "uat90Zbv4KMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq0QoZemz0e1",
        "outputId": "266e3fc8-1ade-4281-be90-90650d4ad79d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_tasks(sentences):\n",
        "    \"\"\"\n",
        "    Identifies sentences containing actionable tasks using refined heuristics.\n",
        "    Returns a list of extracted tasks.\n",
        "    \"\"\"\n",
        "    task_sentences = []\n",
        "    obligation_keywords = {\"has to\", \"should\", \"must\", \"need to\", \"required to\", \"is expected to\"}\n",
        "\n",
        "    for sentence in sentences:\n",
        "        doc = nlp(sentence)\n",
        "        verbs = [token.text for token in doc if token.pos_ == \"VERB\"]\n",
        "\n",
        "        # Check if the sentence contains an obligation phrase\n",
        "        contains_obligation = any(phrase in sentence.lower() for phrase in obligation_keywords)\n",
        "\n",
        "        # Check if the sentence contains a deadline-related word\n",
        "        contains_deadline = any(token.text.lower() in {\"by\", \"before\", \"tomorrow\", \"next week\"} for token in doc)\n",
        "\n",
        "        # A valid task sentence should either contain an obligation phrase or a deadline\n",
        "        if verbs and (contains_obligation or contains_deadline):\n",
        "            task_sentences.append(sentence)\n",
        "\n",
        "    return task_sentences\n",
        "\n",
        "# Example Sentences\n",
        "sentences = [\n",
        "    \"Rahul wakes up early.\",  # Not a task\n",
        "    \"He has to buy snacks for all of us.\",  #  Task\n",
        "    \"We are watching a movie.\",  #  Not a task\n",
        "    \"She should complete the assignment by tomorrow.\",  #  Task\n",
        "    \"They need to submit the report before Monday.\",  #  Task\n",
        "    \"John is going to school.\",  #  Not a task\n",
        "    \"Alex must clean the kitchen today.\"  #  Task\n",
        "]\n",
        "\n",
        "# Extract tasks\n",
        "tasks = extract_tasks(sentences)\n",
        "print(\"Extracted Tasks:\", tasks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77CHavdVw9B2",
        "outputId": "299071fc-da0d-4214-fce3-4a325a1ab12e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Tasks: ['He has to buy snacks for all of us.', 'She should complete the assignment by tomorrow.', 'They need to submit the report before Monday.', 'Alex must clean the kitchen today.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Categorization: Step 3"
      ],
      "metadata": {
        "id": "fh7mWZgH4Pk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize_tasks(task_list):\n",
        "    \"\"\"\n",
        "    Categorizes tasks into predefined categories based on keywords.\n",
        "    \"\"\"\n",
        "    categories = {\n",
        "        \"Shopping\": [\"buy\", \"purchase\", \"order\"],\n",
        "        \"Work/Study\": [\"complete\", \"submit\", \"write\", \"review\", \"study\"],\n",
        "        \"Household Chores\": [\"clean\", \"wash\", \"organize\", \"fix\", \"repair\"],\n",
        "        \"Meetings/Appointments\": [\"schedule\", \"attend\", \"meet\", \"call\"]\n",
        "    }\n",
        "\n",
        "    categorized_tasks = {}\n",
        "\n",
        "    for task in task_list:\n",
        "        assigned_category = \"Uncategorized\"  # Default category if no match\n",
        "\n",
        "        for category, keywords in categories.items():\n",
        "            if any(keyword in task.lower() for keyword in keywords):\n",
        "                assigned_category = category\n",
        "                break  # Stop checking once a category is found\n",
        "\n",
        "        # Add to categorized dictionary\n",
        "        if assigned_category in categorized_tasks:\n",
        "            categorized_tasks[assigned_category].append(task)\n",
        "        else:\n",
        "            categorized_tasks[assigned_category] = [task]\n",
        "\n",
        "    return categorized_tasks\n",
        "\n",
        "# Example Tasks from Step 2\n",
        "tasks = [\n",
        "    \"He has to buy snacks for all of us.\",\n",
        "    \"She should complete the assignment by tomorrow.\",\n",
        "    \"They need to submit the report before Monday.\",\n",
        "    \"Alex must clean the kitchen today.\",\n",
        "    \"John has to attend a meeting at 5 PM.\"\n",
        "]\n",
        "\n",
        "# Categorize Tasks\n",
        "task_categories = categorize_tasks(tasks)\n",
        "print(\"Task Categories:\", task_categories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXNziVYoyJHv",
        "outputId": "1ae9908c-b978-4934-831b-95c4fd5be6ad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task Categories: {'Shopping': ['He has to buy snacks for all of us.'], 'Work/Study': ['She should complete the assignment by tomorrow.', 'They need to submit the report before Monday.'], 'Household Chores': ['Alex must clean the kitchen today.'], 'Meetings/Appointments': ['John has to attend a meeting at 5 PM.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output: Step 4"
      ],
      "metadata": {
        "id": "uqrK8zlO4dzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_who_and_when(task):\n",
        "    \"\"\"\n",
        "    Extracts the responsible person (who) and deadline (when) from a task description.\n",
        "    Uses simple heuristics and regex for 'who' and 'when' extraction.\n",
        "    \"\"\"\n",
        "    # Extract 'who' (simple keyword-based approach)\n",
        "    who = re.search(r\"\\b(he|she|they|alex|john|rahul|you)\\b\", task, re.IGNORECASE)\n",
        "    who = who.group(0) if who else \"Unknown\"  # Default to 'Unknown' if not found\n",
        "\n",
        "    # Extract 'when' (looking for time-related keywords or phrases)\n",
        "    when = None\n",
        "    deadlines = re.findall(r\"\\b(by \\d{1,2} (AM|PM)|tomorrow|today|at \\d{1,2} (AM|PM)|before \\w+)\\b\", task, re.IGNORECASE)\n",
        "    if deadlines:\n",
        "        when = deadlines[0][0]  # Get the first matched deadline phrase\n",
        "\n",
        "    return who, when\n",
        "\n",
        "def categorize_tasks_with_details(task_list):\n",
        "    \"\"\"\n",
        "    Categorizes tasks into predefined categories and adds 'who' and 'when' details.\n",
        "    \"\"\"\n",
        "    categories = {\n",
        "        \"Shopping\": [\"buy\", \"purchase\", \"order\"],\n",
        "        \"Work/Study\": [\"complete\", \"submit\", \"write\", \"review\", \"study\"],\n",
        "        \"Household Chores\": [\"clean\", \"wash\", \"organize\", \"fix\", \"repair\"],\n",
        "        \"Meetings/Appointments\": [\"schedule\", \"attend\", \"meet\", \"call\"]\n",
        "    }\n",
        "\n",
        "    categorized_tasks = {}\n",
        "\n",
        "    for task in task_list:\n",
        "        # First, categorize the task\n",
        "        assigned_category = \"Uncategorized\"  # Default category if no match\n",
        "        for category, keywords in categories.items():\n",
        "            if any(keyword in task.lower() for keyword in keywords):\n",
        "                assigned_category = category\n",
        "                break  # Stop checking once a category is found\n",
        "\n",
        "        # Now, extract who is responsible and when the task should be done\n",
        "        who, when = extract_who_and_when(task)\n",
        "\n",
        "        # Add to categorized dictionary\n",
        "        task_details = {\n",
        "            \"task\": task,\n",
        "            \"who\": who,\n",
        "            \"deadline\": when,\n",
        "            \"category\": assigned_category\n",
        "        }\n",
        "\n",
        "        if assigned_category in categorized_tasks:\n",
        "            categorized_tasks[assigned_category].append(task_details)\n",
        "        else:\n",
        "            categorized_tasks[assigned_category] = [task_details]\n",
        "\n",
        "    return categorized_tasks\n",
        "\n",
        "# Example Tasks from Step 2\n",
        "tasks = [\n",
        "    \"Rahul has to buy snacks for all of us.\",\n",
        "    \"She should complete the assignment by tomorrow.\",\n",
        "    \"They need to submit the report before Monday.\",\n",
        "    \"Alex must clean the kitchen today.\",\n",
        "    \"John has to attend a meeting at 5 PM.\"\n",
        "]\n",
        "\n",
        "# Categorize Tasks and Extract Who and When\n",
        "task_categories = categorize_tasks_with_details(tasks)\n",
        "\n",
        "# Output the Structured Tasks\n",
        "import pandas as pd\n",
        "tasks_df = pd.DataFrame([\n",
        "    {\n",
        "        \"task\": task['task'],\n",
        "        \"who\": task['who'],\n",
        "        \"deadline\": task['deadline'],\n",
        "        \"category\": task['category']\n",
        "    }\n",
        "    for category in task_categories.values() for task in category\n",
        "])\n",
        "\n",
        "# Display the DataFrame\n",
        "tasks_df.to_csv('tasks_output.csv', index=False)\n",
        "print(tasks_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L_iJD38yVZ3",
        "outputId": "849ac641-6661-4d99-c889-283bdce7562f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              task    who       deadline  \\\n",
            "0           Rahul has to buy snacks for all of us.  Rahul           None   \n",
            "1  She should complete the assignment by tomorrow.    She       tomorrow   \n",
            "2    They need to submit the report before Monday.   They  before Monday   \n",
            "3               Alex must clean the kitchen today.   Alex          today   \n",
            "4            John has to attend a meeting at 5 PM.   John        at 5 PM   \n",
            "\n",
            "                category  \n",
            "0               Shopping  \n",
            "1             Work/Study  \n",
            "2             Work/Study  \n",
            "3       Household Chores  \n",
            "4  Meetings/Appointments  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eHYIatK-3n6N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}